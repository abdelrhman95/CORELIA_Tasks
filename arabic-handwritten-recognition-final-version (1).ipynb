{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing the Libraries","metadata":{}},{"cell_type":"code","source":"## Most Important\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom pathlib import Path\nfrom PIL import Image\n\n## less Important\nfrom functools import partial\nimport os\nfrom scipy import stats\nimport missingno as msno\nimport joblib\nimport tarfile\nimport shutil\nimport urllib\nfrom skimage import io\n## Sklearn\nfrom sklearn import datasets\n## Preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n## Metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n## tensorflow & Keras\nimport tensorflow as tf    ## i will use tf for every thing and for keras using tf.keras\nimport keras\nfrom keras.models import Model,Sequential\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, Input,LeakyReLU,AveragePooling2D\nfrom keras.layers.normalization import batch_normalization\nfrom keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2022-03-15T02:22:01.299825Z","iopub.execute_input":"2022-03-15T02:22:01.300081Z","iopub.status.idle":"2022-03-15T02:22:01.312491Z","shell.execute_reply.started":"2022-03-15T02:22:01.300051Z","shell.execute_reply":"2022-03-15T02:22:01.311590Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Analysis","metadata":{}},{"cell_type":"code","source":"#this loads multiple images \nic_train = io.ImageCollection('/kaggle/input/arabic-hwr-ai-pro-intake1/train/*.png')\n\nprint('Type:', type(ic_train))\nprint(\"number of training data\",len(ic_train))","metadata":{"execution":{"iopub.status.busy":"2022-03-15T02:22:29.023514Z","iopub.execute_input":"2022-03-15T02:22:29.023785Z","iopub.status.idle":"2022-03-15T02:23:04.390860Z","shell.execute_reply.started":"2022-03-15T02:22:29.023756Z","shell.execute_reply":"2022-03-15T02:23:04.390041Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"ic_test = io.ImageCollection('/kaggle/input/arabic-hwr-ai-pro-intake1/test/*.png')\n\nprint(\"number of test data\",len(ic_test))","metadata":{"execution":{"iopub.status.busy":"2022-03-15T02:23:50.282784Z","iopub.execute_input":"2022-03-15T02:23:50.283224Z","iopub.status.idle":"2022-03-15T02:23:52.261747Z","shell.execute_reply.started":"2022-03-15T02:23:50.283180Z","shell.execute_reply":"2022-03-15T02:23:52.260997Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_dir='/kaggle/input/arabic-hwr-ai-pro-intake1/train/'\ntrain_imgs=os.listdir(train_dir)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T02:23:52.263431Z","iopub.execute_input":"2022-03-15T02:23:52.263696Z","iopub.status.idle":"2022-03-15T02:23:52.272357Z","shell.execute_reply.started":"2022-03-15T02:23:52.263661Z","shell.execute_reply":"2022-03-15T02:23:52.271600Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing images ","metadata":{}},{"cell_type":"code","source":"##first way:opencv\n ## second way :pil\n# # creating a object (not returned as numpy array ,opens in new window)\nim = Image.open(os.path.join(train_dir,train_imgs[0])) \n# im.show()\n# convert image to numpy array\ndata = np.asarray(im)\nplt.imshow(data);","metadata":{"execution":{"iopub.status.busy":"2022-03-15T02:23:52.273644Z","iopub.execute_input":"2022-03-15T02:23:52.273893Z","iopub.status.idle":"2022-03-15T02:23:52.480957Z","shell.execute_reply.started":"2022-03-15T02:23:52.273853Z","shell.execute_reply":"2022-03-15T02:23:52.480184Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"## third method skimage io\nimage = io.imread(os.path.join(train_dir,train_imgs[0]))\n\nprint(type(image))\nprint(image.dtype)\nprint(image.shape)\nprint(image.min(), image.max())\n\nplt.imshow(image);","metadata":{"execution":{"iopub.status.busy":"2022-03-15T02:23:52.484396Z","iopub.execute_input":"2022-03-15T02:23:52.485375Z","iopub.status.idle":"2022-03-15T02:23:52.693284Z","shell.execute_reply.started":"2022-03-15T02:23:52.484869Z","shell.execute_reply":"2022-03-15T02:23:52.692516Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"## fourth way using plt\nimage = plt.imread(os.path.join(train_dir,train_imgs[0]))\nprint(type(image))\nprint(image.dtype)\nprint(image.shape)\nprint(image.min(), image.max())\nplt.imshow(image);","metadata":{"execution":{"iopub.status.busy":"2022-03-15T02:23:52.694542Z","iopub.execute_input":"2022-03-15T02:23:52.694886Z","iopub.status.idle":"2022-03-15T02:23:52.905886Z","shell.execute_reply.started":"2022-03-15T02:23:52.694846Z","shell.execute_reply":"2022-03-15T02:23:52.905142Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\n# Parameters for our graph; we'll output images in a 4x4 configuration\nnrows = 4\nncols = 4\n\npic_index = 0 # Index for iterating over images","metadata":{"execution":{"iopub.status.busy":"2022-03-15T02:23:52.907006Z","iopub.execute_input":"2022-03-15T02:23:52.907327Z","iopub.status.idle":"2022-03-15T02:23:52.912215Z","shell.execute_reply.started":"2022-03-15T02:23:52.907278Z","shell.execute_reply":"2022-03-15T02:23:52.911594Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Set up matplotlib fig, and size it to fit 4x4 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n\npic_index+=8\n\nnext_img = [os.path.join(train_dir, fname) \n                for fname in train_imgs[ pic_index-8:pic_index] \n               ]\n\nfor i, img_path in enumerate(next_img):\n  # Set up subplot; subplot indices start at 1\n  sp = plt.subplot(nrows, ncols, i + 1)\n  sp.axis('Off') # Don't show axes (or gridlines)\n\n  img = plt.imread(img_path)\n  plt.imshow(img)\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-15T02:23:52.913589Z","iopub.execute_input":"2022-03-15T02:23:52.914037Z","iopub.status.idle":"2022-03-15T02:23:53.330785Z","shell.execute_reply.started":"2022-03-15T02:23:52.914001Z","shell.execute_reply":"2022-03-15T02:23:53.330080Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Preparing Train Data for training ","metadata":{}},{"cell_type":"code","source":"train_labels = pd.read_csv('../input/arabic-hwr-ai-pro-intake1/train.csv')\ntrain_images = Path(r'../input/arabic-hwr-ai-pro-intake1/train')\n\n## read these all training images paths as Series\ntrain_images_paths = pd.Series(sorted(list(train_images.glob(r'*.png'))), name='Filepath').astype(str)\n\ntrain_images_paths.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T02:23:53.332063Z","iopub.execute_input":"2022-03-15T02:23:53.332464Z","iopub.status.idle":"2022-03-15T02:23:53.530941Z","shell.execute_reply.started":"2022-03-15T02:23:53.332426Z","shell.execute_reply":"2022-03-15T02:23:53.530164Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_full_labels = train_labels['label'].values\ntrain_full_set = np.empty((13440, 32, 32, 3), dtype=np.float32)  #take only the first 3 channels\n\nfor idx, path in enumerate(train_images_paths):\n    img = plt.imread(path)\n    img = img[:,:,:3]\n    train_full_set[idx] = img\n    \nprint('train_full_set.shape =>', train_full_set.shape)\nprint('train_full_labels.shape =>', train_full_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T02:23:53.533043Z","iopub.execute_input":"2022-03-15T02:23:53.533853Z","iopub.status.idle":"2022-03-15T02:24:04.112876Z","shell.execute_reply.started":"2022-03-15T02:23:53.533813Z","shell.execute_reply":"2022-03-15T02:24:04.112021Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Preparing Test Data :","metadata":{}},{"cell_type":"code","source":"test_labels = pd.read_csv('../input/arabic-hwr-ai-pro-intake1/test.csv')\ntest_images = Path(r'../input/arabic-hwr-ai-pro-intake1/test')\n\n## read these all training images paths as Series\ntest_images_paths = pd.Series(sorted(list(test_images.glob(r'*.png'))), name='Filepath').astype(str)\n\ntest_images_paths.head()\n\n\nprint('Number of Instances in test_set is', len(test_images_paths))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-15T02:24:04.116840Z","iopub.execute_input":"2022-03-15T02:24:04.117136Z","iopub.status.idle":"2022-03-15T02:24:04.175842Z","shell.execute_reply.started":"2022-03-15T02:24:04.117110Z","shell.execute_reply":"2022-03-15T02:24:04.174973Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"test_full_set = np.empty((3360, 32, 32, 3), dtype=np.float32)  #take only the first 3 channels\n\nfor idx, path in enumerate(test_images_paths):\n    img = plt.imread(path)\n    img = img[:,:,:3]\n    test_full_set[idx] = img\n    \nprint('test_full_set.shape =>', test_full_set.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T02:24:04.177362Z","iopub.execute_input":"2022-03-15T02:24:04.177638Z","iopub.status.idle":"2022-03-15T02:24:06.940619Z","shell.execute_reply.started":"2022-03-15T02:24:04.177604Z","shell.execute_reply":"2022-03-15T02:24:06.939817Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Model Building","metadata":{}},{"cell_type":"markdown","source":"## First Model","metadata":{}},{"cell_type":"code","source":"def create_model():\n\n    \n    model = Sequential()\n\n    model.add(Conv2D(filters=64, kernel_size=3, input_shape=(32, 32, 3), activation='relu'))\n    model.add(Conv2D(filters=64, kernel_size=3, padding=\"same\", activation='relu'))\n    model.add(Conv2D(filters=64, kernel_size=3, padding=\"same\", activation='relu'))\n    model.add(MaxPooling2D(pool_size=2,strides=(1, 1)))\n    \n    \n    model.add(Conv2D(filters=128, kernel_size=3, activation='relu',padding=\"same\"))\n    model.add(Conv2D(filters=128, kernel_size=3, padding=\"valid\", activation='relu'))\n    \n    model.add(MaxPooling2D(pool_size=2,strides=(1, 1)))\n    \n    \n    model.add(Conv2D(filters=256, kernel_size=3, padding=\"same\", activation='relu'))\n    model.add(Conv2D(filters=256, kernel_size=3, padding=\"valid\", activation='relu'))\n    model.add(MaxPooling2D(pool_size=2,strides=(1, 1)))\n    model.add(AveragePooling2D())\n    \n    model.add(Flatten())\n    model.add(Dropout(0.5))\n    model.add(Dense(29, activation='softmax'))\n    \n    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-03-15T02:24:06.941872Z","iopub.execute_input":"2022-03-15T02:24:06.942247Z","iopub.status.idle":"2022-03-15T02:24:06.955512Z","shell.execute_reply.started":"2022-03-15T02:24:06.942214Z","shell.execute_reply":"2022-03-15T02:24:06.954872Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation :","metadata":{}},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False,\n        validation_split = 0.1)  # randomly flip images","metadata":{"execution":{"iopub.status.busy":"2022-03-15T02:24:06.956753Z","iopub.execute_input":"2022-03-15T02:24:06.957172Z","iopub.status.idle":"2022-03-15T02:24:06.971937Z","shell.execute_reply.started":"2022-03-15T02:24:06.957138Z","shell.execute_reply":"2022-03-15T02:24:06.971343Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"callback_list = [\n    ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=15),\n    EarlyStopping(monitor='val_loss', min_delta=0.0005, patience=25),\n    ModelCheckpoint(\n    filepath=\"best.hdf5\",\n    monitor='val_accuracy', \n    verbose=1, \n    save_best_only=True, \n    mode='max')\n    ]","metadata":{"execution":{"iopub.status.busy":"2022-03-15T02:24:06.973374Z","iopub.execute_input":"2022-03-15T02:24:06.973817Z","iopub.status.idle":"2022-03-15T02:24:06.983506Z","shell.execute_reply.started":"2022-03-15T02:24:06.973783Z","shell.execute_reply":"2022-03-15T02:24:06.982759Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 150\nBATCH_SIZE = 128\nENSEMBLES = 10 # number of models to ensemble\nresult_list = [] # store results for correlation matrix\nhistories = [] # store histories for training and validation curves\nresults = np.zeros((test_full_set.shape[0],29))\n\n\n\nfor i in range(ENSEMBLES):\n    # split training and validation sets\n    X_train_tmp, X_val, y_train_tmp, y_val = train_test_split(train_full_set, train_full_labels, test_size=0.1, random_state=i)\n    # create model\n    model = create_model()\n    # fit the model\n    print('training No.', i)\n    history = model.fit(datagen.flow(X_train_tmp, y_train_tmp, batch_size=BATCH_SIZE),\n                   epochs=EPOCHS,\n                   callbacks=callback_list,\n                   validation_data=(X_val, y_val),\n                   )\n    # save results\n    histories.append(history)\n    result = model.predict(test_full_set)\n    results += result\n    result_list.append(result)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T02:24:06.985274Z","iopub.execute_input":"2022-03-15T02:24:06.986191Z","iopub.status.idle":"2022-03-15T03:55:36.107613Z","shell.execute_reply.started":"2022-03-15T02:24:06.986155Z","shell.execute_reply":"2022-03-15T03:55:36.106734Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# check correlation of each predictions\ncorr_preds = pd.DataFrame([np.argmax(result, axis=1) for result in result_list]).T.corr()\nfig = sns.heatmap(corr_preds, annot=True, fmt='.3f', cmap='rainbow')\nfig.set_title('Predictions correlation matrix', fontsize=16, y=1.05)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T03:55:36.108987Z","iopub.execute_input":"2022-03-15T03:55:36.109259Z","iopub.status.idle":"2022-03-15T03:55:36.910576Z","shell.execute_reply.started":"2022-03-15T03:55:36.109222Z","shell.execute_reply":"2022-03-15T03:55:36.909874Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"loss_all_data, acc_all_data = model.evaluate(train_full_set, train_full_labels, verbose=0)\nprint('loss_all_data =>', loss_all_data)\nprint('acc_all_data =>', acc_all_data)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T03:55:36.911684Z","iopub.execute_input":"2022-03-15T03:55:36.912129Z","iopub.status.idle":"2022-03-15T03:55:39.015781Z","shell.execute_reply.started":"2022-03-15T03:55:36.912082Z","shell.execute_reply":"2022-03-15T03:55:39.014988Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(2, 1, figsize=(12,6))\n\nfor e in range(ENSEMBLES):\n    loss = histories[e].history['loss']\n    val_loss = histories[e].history['val_loss']\n    acc = histories[e].history['accuracy']\n    val_acc = histories[e].history['val_accuracy']\n    ax[0].set_title('loss')\n    ax[0].plot(loss, 'b', linewidth=1)\n    ax[0].plot(val_loss, 'r', linewidth=1)\n    ax[0].grid(color='black', linestyle='-', linewidth=0.2)\n    ax[1].set_title('accuracy')\n    ax[1].plot(acc, 'b', linewidth=1)\n    ax[1].plot(val_acc, 'r', linewidth=1)\n    ax[1].grid(color='black', linestyle='-', linewidth=0.2)\n    \nax[0].legend(['Training loss', 'Validation loss'], shadow=True)     \nax[1].legend(['Training accuracy', 'Validation accuracy'], shadow=True)\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T03:55:39.016938Z","iopub.execute_input":"2022-03-15T03:55:39.017275Z","iopub.status.idle":"2022-03-15T03:55:39.575123Z","shell.execute_reply.started":"2022-03-15T03:55:39.017236Z","shell.execute_reply":"2022-03-15T03:55:39.574459Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"code","source":"results = np.argmax(results, axis=1)\nresults = pd.Series(results, name='Label')","metadata":{"execution":{"iopub.status.busy":"2022-03-15T03:55:39.576393Z","iopub.execute_input":"2022-03-15T03:55:39.576771Z","iopub.status.idle":"2022-03-15T03:55:39.581843Z","shell.execute_reply.started":"2022-03-15T03:55:39.576735Z","shell.execute_reply":"2022-03-15T03:55:39.581148Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"test_labels['label'] = results","metadata":{"execution":{"iopub.status.busy":"2022-03-15T03:55:39.583478Z","iopub.execute_input":"2022-03-15T03:55:39.583984Z","iopub.status.idle":"2022-03-15T03:55:39.592691Z","shell.execute_reply.started":"2022-03-15T03:55:39.583948Z","shell.execute_reply":"2022-03-15T03:55:39.591908Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"test_labels['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T03:55:39.594442Z","iopub.execute_input":"2022-03-15T03:55:39.595013Z","iopub.status.idle":"2022-03-15T03:55:39.605893Z","shell.execute_reply.started":"2022-03-15T03:55:39.594972Z","shell.execute_reply":"2022-03-15T03:55:39.605200Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"\n test_labels   \n","metadata":{"execution":{"iopub.status.busy":"2022-03-15T03:55:39.607207Z","iopub.execute_input":"2022-03-15T03:55:39.607485Z","iopub.status.idle":"2022-03-15T03:55:39.623886Z","shell.execute_reply.started":"2022-03-15T03:55:39.607451Z","shell.execute_reply":"2022-03-15T03:55:39.623111Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Saving Results","metadata":{}},{"cell_type":"code","source":"test_labels[['id', 'label']].to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T03:55:39.625051Z","iopub.execute_input":"2022-03-15T03:55:39.625324Z","iopub.status.idle":"2022-03-15T03:55:39.639535Z","shell.execute_reply.started":"2022-03-15T03:55:39.625277Z","shell.execute_reply":"2022-03-15T03:55:39.638886Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}